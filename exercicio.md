# üßä Exerc√≠cio Pr√°tico: Pipeline Completo com Apache Iceberg

## üéØ Objetivo

Desenvolver um pipeline completo de dados utilizando **Apache Iceberg**, aplicando todos os conceitos aprendidos na aula: versionamento, particionamento, schema evolution, compacta√ß√£o e integra√ß√£o com bancos relacionais.

---

## üìã Cen√°rio Empresarial

Voc√™ √© um **Engenheiro de Dados** em uma empresa de e-commerce que precisa implementar um data lake moderno usando Apache Iceberg. O sistema deve:

- Processar dados de vendas de m√∫ltiplas fontes
- Manter hist√≥rico completo com versionamento
- Permitir evolu√ß√£o de schema sem downtime
- Integrar dados transacionais (PostgreSQL) com dados anal√≠ticos (Iceberg)
- Garantir performance atrav√©s de particionamento e compacta√ß√£o

---

## üöÄ **PARTE 1: Cria√ß√£o da Arquitetura Base **

### **Tarefa 1.1: Setup do Ambiente**
Crie um novo notebook chamado `exercicio_final.ipynb` e configure o ambiente Spark com Iceberg.

**Requisitos:**
- Configure SparkSession com nome "EcommerceDataLake"
- Habilite extens√µes Iceberg
- Configure cat√°logo hadoop_catalog
- Defina warehouse em `/home/tavares/warehouse`

### **Tarefa 1.2: Cria√ß√£o da Tabela Principal**
Crie uma tabela Iceberg chamada `vendas_ecommerce` com o seguinte schema:

```sql
CREATE TABLE hadoop_catalog.default.vendas_ecommerce (
    venda_id INT,
    produto_nome STRING,
    categoria STRING,
    quantidade INT,
    preco_unitario DOUBLE,
    data_venda DATE,
    cliente_id STRING,
    vendedor_id INT
)
USING iceberg
PARTITIONED BY (year(data_venda), categoria)
```

---

## üìä **PARTE 2: Opera√ß√µes com Versionamento **

### **Tarefa 2.1: Inser√ß√£o de Dados Hist√≥ricos**
Insira dados de vendas de 2023:

```sql
INSERT INTO hadoop_catalog.default.vendas_ecommerce VALUES
(1, 'Notebook Dell', 'Eletr√¥nicos', 2, 2500.00, DATE('2023-01-15'), 'CLI001', 101),
(2, 'Mouse Logitech', 'Eletr√¥nicos', 5, 80.00, DATE('2023-01-16'), 'CLI002', 102),
(3, 'Mesa Escrit√≥rio', 'M√≥veis', 1, 800.00, DATE('2023-02-10'), 'CLI003', 101),
(4, 'Cadeira Gamer', 'M√≥veis', 2, 600.00, DATE('2023-02-15'), 'CLI001', 103),
(5, 'Smartphone Samsung', 'Eletr√¥nicos', 1, 1200.00, DATE('2023-03-20'), 'CLI004', 102)
```

### **Tarefa 2.2: Inser√ß√£o de Dados de 2024**
Adicione vendas de 2024:

```sql
INSERT INTO hadoop_catalog.default.vendas_ecommerce VALUES
(6, 'Tablet iPad', 'Eletr√¥nicos', 1, 3000.00, DATE('2024-01-10'), 'CLI002', 101),
(7, 'Sof√° 3 Lugares', 'M√≥veis', 1, 1500.00, DATE('2024-01-20'), 'CLI005', 103),
(8, 'Monitor 4K', 'Eletr√¥nicos', 2, 800.00, DATE('2024-02-05'), 'CLI003', 102)
```

### **Tarefa 2.3: An√°lise de Snapshots**
- Liste todos os snapshots criados
- Identifique quantos snapshots foram gerados
- Mostre o hist√≥rico da tabela

### **Tarefa 2.4: Time Travel**
- Consulte apenas os dados de 2023 usando o primeiro snapshot
- Compare com os dados atuais da tabela

---

## üîÑ **PARTE 3: Schema Evolution**

### **Tarefa 3.1: Evolu√ß√£o do Schema**
Evolua o schema da tabela adicionando as seguintes colunas:
- `desconto DOUBLE` (para armazenar percentual de desconto)
- `canal_venda STRING` (online, loja_fisica, telefone)

### **Tarefa 3.2: Inser√ß√£o com Novo Schema**
Insira dados usando o schema evolu√≠do:

```sql
INSERT INTO hadoop_catalog.default.vendas_ecommerce VALUES
(9, 'Headset Gamer', 'Eletr√¥nicos', 3, 250.00, DATE('2024-03-15'), 'CLI006', 101, 10.0, 'online'),
(10, 'Mesa Centro', 'M√≥veis', 1, 400.00, DATE('2024-03-20'), 'CLI007', 102, 5.0, 'loja_fisica')
```

### **Tarefa 3.3: Verifica√ß√£o de Compatibilidade**
- Mostre que dados antigos t√™m valores NULL nas novas colunas
- Confirme que todas as consultas ainda funcionam

---

## üîß **PARTE 4: Opera√ß√µes ACID e Merge **

### **Tarefa 4.1: Simula√ß√£o de Erro**
Fa√ßa uma atualiza√ß√£o "problem√°tica":

```sql
UPDATE hadoop_catalog.default.vendas_ecommerce 
SET preco_unitario = preco_unitario * 100 
WHERE categoria = 'Eletr√¥nicos'
```

### **Tarefa 4.2: Rollback**
- Identifique o snapshot antes da atualiza√ß√£o problem√°tica
- Execute rollback para esse snapshot
- Verifique que os dados voltaram ao estado anterior

### **Tarefa 4.3: Opera√ß√£o MERGE**
Crie uma view tempor√°ria com atualiza√ß√µes e execute MERGE INTO:

```sql
CREATE OR REPLACE TEMPORARY VIEW vendas_updates AS
SELECT 1 as venda_id, 'Notebook Dell UPDATED' as produto_nome, 'Eletr√¥nicos' as categoria, 
       2 as quantidade, 2600.00 as preco_unitario, DATE('2023-01-15') as data_venda, 
       'CLI001' as cliente_id, 101 as vendedor_id, 0.0 as desconto, 'online' as canal_venda
UNION ALL
SELECT 11 as venda_id, 'Teclado Mec√¢nico' as produto_nome, 'Eletr√¥nicos' as categoria,
       4 as quantidade, 300.00 as preco_unitario, DATE('2024-04-01') as data_venda,
       'CLI008' as cliente_id, 103 as vendedor_id, 15.0 as desconto, 'online' as canal_venda
```

Execute MERGE INTO para atualizar registro existente e inserir novo.

---

## üìà **PARTE 5: Otimiza√ß√£o e An√°lise **

### **Tarefa 5.1: An√°lise de Fragmenta√ß√£o**
- Use metadados para analisar quantos arquivos foram criados
- Identifique se h√° necessidade de compacta√ß√£o
- Mostre estat√≠sticas de arquivos por parti√ß√£o

### **Tarefa 5.2: Compacta√ß√£o**
- Execute compacta√ß√£o usando `rewrite_data_files`
- Compare n√∫mero de arquivos antes e depois
- Verifique que os dados permanecem √≠ntegros

### **Tarefa 5.3: An√°lise de Performance**
- Demonstre partition pruning consultando apenas dados de 2024
- Mostre consulta otimizada por categoria
- Use metadados para mostrar efici√™ncia das consultas

### **Tarefa 5.4: Limpeza de Snapshots**
- Execute `expire_snapshots` mantendo apenas os √∫ltimos 3 snapshots
- Verifique quantos arquivos foram removidos

---

## üèÜ **ENTREGA FINAL**

### **Relat√≥rio de An√°lise**
Crie uma c√©lula markdown final com:

1. **Resumo Executivo**:
   - Quantos snapshots foram criados no total?
   - Qual foi a redu√ß√£o de arquivos ap√≥s compacta√ß√£o?
   - Quantas parti√ß√µes foram criadas?

2. **Benef√≠cios Observados**:
   - Liste 3 vantagens do Iceberg que voc√™ observou na pr√°tica
   - Compare com o que seria necess√°rio usando Parquet tradicional

3. **Casos de Uso Identificados**:
   - Descreva 2 cen√°rios empresariais onde este pipeline seria √∫til
   - Explique como o versionamento ajudaria em cada caso

### **Consultas de Valida√ß√£o**
Inclua estas consultas para validar seu trabalho:

```sql
-- 1. Total de registros por ano
SELECT year(data_venda) as ano, COUNT(*) as total_vendas 
FROM hadoop_catalog.default.vendas_ecommerce 
GROUP BY year(data_venda) 
ORDER BY ano;

-- 2. Vendas por categoria com desconto m√©dio
SELECT categoria, 
       COUNT(*) as total_vendas,
       ROUND(AVG(COALESCE(desconto, 0.0)), 2) as desconto_medio,
       ROUND(SUM(preco_unitario * quantidade), 2) as receita_total
FROM hadoop_catalog.default.vendas_ecommerce 
GROUP BY categoria;

-- 3. An√°lise temporal de snapshots
SELECT operation, COUNT(*) as num_operacoes 
FROM hadoop_catalog.default.vendas_ecommerce.snapshots 
GROUP BY operation;
```

---

## üìù **Crit√©rios de Avalia√ß√£o**

| Crit√©rio | Pontos | Descri√ß√£o |
|----------|--------|-----------|
| **Configura√ß√£o** | 25 | Setup correto do Spark e cria√ß√£o da tabela |
| **Versionamento** | 25 | Snapshots, time travel e rollbacks |
| **Schema Evolution** | 20 | Evolu√ß√£o sem downtime e compatibilidade |
| **ACID Operations** | 15 | UPDATE, MERGE INTO e transa√ß√µes |
| **Otimiza√ß√£o** | 15 | Compacta√ß√£o, an√°lise de metadados e performance |

### **Pontua√ß√£o Extra (+10 pontos)**
- Implementar particionamento adicional por `canal_venda`
- Criar an√°lise avan√ßada usando m√∫ltiplas tabelas de metadados
- Demonstrar integra√ß√£o com dados do PostgreSQL (tabela customers)

---

## üéì **Dicas para Sucesso**

1. **Execute os notebooks em ordem** antes de come√ßar o exerc√≠cio
2. **Use apenas SQL puro** para evitar erros de serializa√ß√£o
3. **Documente cada etapa** com c√©lulas markdown explicativas
4. **Verifique sempre** a integridade dos dados ap√≥s cada opera√ß√£o
5. **Monitore snapshots** para entender o versionamento
6. **Aproveite os metadados** para an√°lises avan√ßadas

---

## üèÅ **Entrega**

Salve o notebook `exercicio_final.ipynb` com todas as tarefas completas e documentadas. O exerc√≠cio deve demonstrar dom√≠nio pr√°tico dos conceitos fundamentais do Apache Iceberg aplicados em um cen√°rio empresarial realista.

**Boa sorte! üöÄ**