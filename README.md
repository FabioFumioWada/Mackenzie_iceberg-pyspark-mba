# ğŸ§Š Apache Iceberg com PySpark: Data Lakes Modernos e GovernanÃ§a de Dados

Este repositÃ³rio foi desenvolvido para a disciplina **Data Collection** do MBA em Engenharia de Dados, focando no **Apache Iceberg** - o formato de tabela open-source que revoluciona o gerenciamento de dados em data lakes.

## ğŸ¯ Objetivos da Aula

Demonstrar na prÃ¡tica os recursos avanÃ§ados do Apache Iceberg atravÃ©s de exemplos hands-on:

- **ACID Transactions**: Garantia de consistÃªncia em operaÃ§Ãµes
- **Schema Evolution**: EvoluÃ§Ã£o de esquema sem downtime
- **Time Travel**: Consultas histÃ³ricas e rollbacks
- **Partition Evolution**: MudanÃ§a de estratÃ©gias de particionamento
- **CompactaÃ§Ã£o**: OtimizaÃ§Ã£o de performance e armazenamento
- **Metadados Ricos**: GovernanÃ§a e monitoramento avanÃ§ado

## ğŸ“š ConteÃºdo ProgramÃ¡tico

### ğŸ”§ **MÃ³dulo 1: Fundamentos**
- **001 - Snapshots e TimeTravel**: Versionamento e consultas histÃ³ricas
- **002 - Particionamento de Dados**: EstratÃ©gias de particionamento otimizado
- **003 - Rollbacks**: ReversÃ£o de operaÃ§Ãµes e recuperaÃ§Ã£o de dados

### ğŸš€ **MÃ³dulo 2: OperaÃ§Ãµes AvanÃ§adas**
- **004 - Incorporando Dados Existentes**: MigraÃ§Ã£o de Parquet para Iceberg
- **005 - Merge com Banco Relacional**: IntegraÃ§Ã£o PostgreSQL + Iceberg
- **006 - EvoluÃ§Ã£o de Schema**: MudanÃ§as de estrutura sem downtime

### âš¡ **MÃ³dulo 3: OtimizaÃ§Ã£o e GovernanÃ§a**
- **007 - CompactaÃ§Ã£o de Dados**: OtimizaÃ§Ã£o de arquivos pequenos
- **008 - Uso de Metadados e CatÃ¡logo**: GovernanÃ§a e monitoramento

## ğŸ—ï¸ Arquitetura do Ambiente

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Jupyter Lab   â”‚    â”‚   Apache Spark   â”‚    â”‚  PostgreSQL     â”‚
â”‚   (Port 8888)   â”‚â—„â”€â”€â–ºâ”‚   + Iceberg      â”‚â—„â”€â”€â–ºâ”‚  (Port 2001)    â”‚
â”‚                 â”‚    â”‚   (Port 4040)    â”‚    â”‚  Northwind DB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Docker Network    â”‚
                    â”‚  (172.16.240.0/24)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‚ Estrutura do Projeto

```
dataqualitySpark/
â”œâ”€â”€ ğŸ“ notebooks/           # Notebooks da aula
â”‚   â”œâ”€â”€ 001 - Snapshots e TimeTravel.ipynb
â”‚   â”œâ”€â”€ 002 - ParticaoDados.ipynb
â”‚   â”œâ”€â”€ 003 - Rollbacks.ipynb
â”‚   â”œâ”€â”€ 004 - IncorporandoDadosExistentes.ipynb
â”‚   â”œâ”€â”€ 005 - FazendoMergeBancoRelacional.ipynb
â”‚   â”œâ”€â”€ 006 - EvolucaoSchema.ipynb
â”‚   â”œâ”€â”€ 007 - CompactacaoDados.ipynb
â”‚   â”œâ”€â”€ 008 - UsoMetadadosCatalgo.ipynb
â”‚   â”œâ”€â”€ data/               # Dados de exemplo
â”‚   â””â”€â”€ spark_config.py     # ConfiguraÃ§Ãµes do Spark
â”œâ”€â”€ ğŸ“ data/               # Datasets
â”‚   â””â”€â”€ logistica_raw.csv  # Dataset para exercÃ­cios
â”œâ”€â”€ ğŸ“ db/                 # Banco de dados
â”‚   â””â”€â”€ northwind.sql      # Schema PostgreSQL
â”œâ”€â”€ ğŸ³ docker-compose.yml  # OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ ğŸ³ Dockerfile          # Imagem customizada
â”œâ”€â”€ ğŸ“‹ exercicio.md        # ExercÃ­cio prÃ¡tico
â””â”€â”€ ğŸ“– readme.md           # Este arquivo
```

## ğŸš€ Setup e ExecuÃ§Ã£o

### PrÃ©-requisitos
- [Docker](https://docs.docker.com/get-docker/) 20.10+
- [Docker Compose](https://docs.docker.com/compose/install/) 2.0+
- 8GB RAM disponÃ­vel
- 10GB espaÃ§o em disco

### ğŸ”¥ InÃ­cio RÃ¡pido

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/AleTavares/dataqualitySpark.git
   cd dataqualitySpark
   ```

2. **Inicie o ambiente**:
   ```bash
   docker-compose up -d --build
   ```

3. **Acesse o Jupyter Lab**:
   ```
   http://localhost:8888
   Token: tavares1234
   ```

4. **Acesse o Spark UI** (opcional):
   ```
   http://localhost:4040
   ```

5. **PostgreSQL** (para exercÃ­cios de integraÃ§Ã£o):
   ```
   Host: localhost
   Port: 2001
   Database: northwind
   User: postgres
   Password: postgres
   ```

### ğŸ›‘ Parar o ambiente
```bash
docker-compose down
```

## ğŸ“ Roteiro de Estudos

### **Parte 1: Conceitos Fundamentais (45 min)**
1. Execute `001 - Snapshots e TimeTravel.ipynb`
   - Entenda o conceito de snapshots
   - Pratique consultas time travel
   
2. Execute `002 - ParticaoDados.ipynb`
   - Aprenda estratÃ©gias de particionamento
   - Compare performance com/sem partiÃ§Ãµes

3. Execute `003 - Rollbacks.ipynb`
   - Pratique operaÃ§Ãµes de rollback
   - Entenda recuperaÃ§Ã£o de dados

### **Parte 2: OperaÃ§Ãµes AvanÃ§adas (60 min)**
4. Execute `004 - IncorporandoDadosExistentes.ipynb`
   - Migre dados Parquet para Iceberg
   - Compare funcionalidades

5. Execute `005 - FazendoMergeBancoRelacional.ipynb`
   - Integre PostgreSQL com Iceberg
   - Pratique operaÃ§Ãµes MERGE

6. Execute `006 - EvolucaoSchema.ipynb`
   - Evolua schemas sem downtime
   - Teste compatibilidade retroativa

### **Parte 3: OtimizaÃ§Ã£o e GovernanÃ§a (45 min)**
7. Execute `007 - CompactacaoDados.ipynb`
   - Otimize arquivos pequenos
   - Monitore performance

8. Execute `008 - UsoMetadadosCatalgo.ipynb`
   - Explore metadados ricos
   - Implemente governanÃ§a

### **Parte 4: ExercÃ­cio PrÃ¡tico (30 min)**
9. Complete o `exercicio.md`
   - Aplique todos os conceitos aprendidos
   - Desenvolva pipeline completo

## ğŸ”§ Tecnologias Utilizadas

| Tecnologia | VersÃ£o | PropÃ³sito |
|------------|--------|-----------|
| **Apache Spark** | 3.3.0 | Engine de processamento |
| **Apache Iceberg** | 1.6.1 | Formato de tabela |
| **PostgreSQL** | 14.19 | Banco relacional |
| **Python** | 3.11 | Linguagem principal |
| **Jupyter Lab** | Latest | Ambiente de desenvolvimento |
| **Docker** | 20.10+ | ContainerizaÃ§Ã£o |

## ğŸ¯ Diferenciais do Apache Iceberg

### âœ… **Vantagens sobre Formatos Tradicionais**

| Recurso | Parquet/ORC | **Apache Iceberg** |
|---------|-------------|-------------------|
| ACID Transactions | âŒ | âœ… |
| Schema Evolution | âŒ | âœ… |
| Time Travel | âŒ | âœ… |
| Rollbacks | âŒ | âœ… |
| Partition Evolution | âŒ | âœ… |
| Hidden Partitioning | âŒ | âœ… |
| Metadados Ricos | âŒ | âœ… |

### ğŸš€ **Casos de Uso Empresariais**
- **Data Warehousing**: SubstituiÃ§Ã£o de soluÃ§Ãµes proprietÃ¡rias
- **Data Lakes**: GovernanÃ§a e qualidade de dados
- **Analytics**: Consultas histÃ³ricas e auditoria
- **Machine Learning**: Datasets versionados e reproduzÃ­veis
- **Compliance**: Rastreabilidade e auditoria completa

## ğŸ¤ ContribuiÃ§Ãµes

Este material foi desenvolvido para fins educacionais. SugestÃµes e melhorias sÃ£o bem-vindas atravÃ©s de issues e pull requests.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ“ Suporte

Para dÃºvidas sobre o conteÃºdo da aula:
- Abra uma [issue](https://github.com/AleTavares/dataqualitySpark/issues)
- Entre em contato durante a aula

---

**ğŸ“ MBA Engenharia de Dados - Data Collection**  
*Transformando dados em valor atravÃ©s do Apache Iceberg*